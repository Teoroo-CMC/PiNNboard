{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This documentation shows how to train a neural network on the QM9 dataset and visualize the network with PiNNboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from pinn.models import potential_model\n",
    "from pinn.networks import pinet\n",
    "from pinn.utils import get_atomic_dress\n",
    "from pinn.io import load_qm9, sparse_batch\n",
    "from tensorboard_plugin_pinnboard.summary import pinnboard_summary\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob('/home/yunqi/datasets/QM9/dsgdb9nsd/*.xyz')\n",
    "\n",
    "with open('/home/yunqi/datasets/QM9/3195404') as f:\n",
    "    lines = f.readlines()\n",
    "out = [int(l.split()[0]) for l in lines[9:-1]]\n",
    "filelist = [i for i in filelist if int(i[-10:-4]) not in out]\n",
    "\n",
    "print(\"{} structures in total.\".format(len(filelist)))\n",
    "dataset = lambda: load_qm9(filelist, split={'train':8, 'test':2}, seed=0)\n",
    "dress, error = get_atomic_dress(dataset()['train'].apply(sparse_batch(100)),[1,6,7,8,9], max_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the training process\n",
    "\n",
    "Note the `keep_checkpoint_max` is set to `None` in the RunConfig, \n",
    "this keeps every checkpoint so that we can use it later to\n",
    "produce the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'model_dir': 'PiNet_QM9',\n",
    "    'network': 'pinet',\n",
    "    'network_params': {\n",
    "        'ii_nodes':[5],\n",
    "        'pi_nodes':[5],\n",
    "        'pp_nodes':[5],\n",
    "        'en_nodes':[3, 3],\n",
    "        'depth': 2,\n",
    "        'rc': 4.5,\n",
    "        'basis_type': 'gaussian',\n",
    "        'n_basis': 10,\n",
    "        'atom_types': [1, 6, 7, 8, 9]},\n",
    "    'model_params':{\n",
    "        'e_scale': 627.5,\n",
    "        'e_dress': dress,\n",
    "        'learning_rate':3e-3,\n",
    "        'decay_rate': 0.994,\n",
    "    }}\n",
    "\n",
    "config = tf.estimator.RunConfig(log_step_count_steps=5000,\n",
    "                                keep_checkpoint_max=None,\n",
    "                                save_summary_steps=5000,\n",
    "                                save_checkpoints_secs=60)\n",
    "\n",
    "\n",
    "pre_fn = lambda tensors: pinet(tensors, preprocess=True, **params['network_params'])\n",
    "train = lambda: dataset()['train'].apply(sparse_batch(100)).map(pre_fn).cache().repeat().shuffle(500)\n",
    "test = lambda: dataset()['test'].apply(sparse_batch(100)).map(pre_fn)\n",
    "                         \n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train, max_steps=3e6)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=test, throttle_secs=300)\n",
    "\n",
    "model = potential_model(params, config)\n",
    "tf.estimator.train_and_evaluate(model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the summary\n",
    "\n",
    "Load all the checkpoints and write a summary for each of them.\n",
    "\n",
    "*This might not be the best way to do this. It should also be possible to save the automatically during training and evaluation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ckpt = ['.'.join(s.split('.')[:-1]) for s in glob('PiNet_QM9/*ckpt*index')]\n",
    "all_ckpt.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "params = yaml.load(open('PiNet_QM9/params.yml'))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# We only take the first 10 elements in the test set and use them for the visualization\n",
    "tensors = dataset()['test'].apply(sparse_batch(10)).take(1).repeat().make_one_shot_iterator().get_next()\n",
    "pinet(tensors, **params['network_params'])\n",
    "\n",
    "summary_ops = pinnboard_summary(params)\n",
    "writer = tf.summary.FileWriter('PiNet_QM9/pinnboard')\n",
    "sess = tf.Session()\n",
    " \n",
    "for (i,ckpt) in enumerate(all_ckpt):\n",
    "    tf.train.init_from_checkpoint(ckpt, {'/':'/'})\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    summary = sess.run(summary_ops)\n",
    "    for s in summary.values():\n",
    "        writer.add_summary(s, i)\n",
    "writer.close()  \n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
